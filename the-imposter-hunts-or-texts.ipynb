{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":105874,"databundleVersionId":12964783,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-16T14:43:03.483587Z","iopub.execute_input":"2025-09-16T14:43:03.484262Z","iopub.status.idle":"2025-09-16T14:43:03.488627Z","shell.execute_reply.started":"2025-09-16T14:43:03.484232Z","shell.execute_reply":"2025-09-16T14:43:03.487495Z"},"_kg_hide-output":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/fake-or-real-the-impostor-hunt/data/train.csv') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T14:58:56.711537Z","iopub.execute_input":"2025-09-16T14:58:56.712256Z","iopub.status.idle":"2025-09-16T14:58:56.743718Z","shell.execute_reply.started":"2025-09-16T14:58:56.712226Z","shell.execute_reply":"2025-09-16T14:58:56.742831Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"texts = []\nlabels = []  \narticle_ids = []\n\ndef get_article_folder_name(article_id):\n    \"\"\"Convert numeric ID to folder name format: article_XXXX\"\"\"\n    return f\"article_{str(article_id).zfill(4)}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T15:13:25.735912Z","iopub.execute_input":"2025-09-16T15:13:25.736566Z","iopub.status.idle":"2025-09-16T15:13:25.740956Z","shell.execute_reply.started":"2025-09-16T15:13:25.736537Z","shell.execute_reply":"2025-09-16T15:13:25.740047Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def load_article_data(article_id, real_text_id, data_dir='/kaggle/input/fake-or-real-the-impostor-hunt/data/train'):\n    # Convert numeric ID to folder name\n    folder_name = get_article_folder_name(article_id)\n    folder_path = os.path.join(data_dir, folder_name)\n    \n    try:\n        with open(os.path.join(folder_path, 'file_1.txt'), 'r', encoding='utf-8') as f:\n            text1 = f.read()\n        with open(os.path.join(folder_path, 'file_2.txt'), 'r', encoding='utf-8') as f:\n            text2 = f.read()\n        \n        return {\n            'real_text': text1 if real_text_id == 1 else text2,\n            'fake_text': text2 if real_text_id == 1 else text1\n        }\n    except FileNotFoundError as e:\n        print(f\"Error loading article {article_id}: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T15:13:29.682539Z","iopub.execute_input":"2025-09-16T15:13:29.682863Z","iopub.status.idle":"2025-09-16T15:13:29.690078Z","shell.execute_reply.started":"2025-09-16T15:13:29.682841Z","shell.execute_reply":"2025-09-16T15:13:29.688736Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_data = []\nfor idx, row in train_df.iterrows():\n    article_id = row['id']\n    real_text_id = row['real_text_id']\n    \n    article_data = load_article_data(article_id, real_text_id)\n    \n    if article_data:\n        train_data.extend([\n            {'article_id': article_id, 'text': article_data['real_text'], 'label': 1},\n            {'article_id': article_id, 'text': article_data['fake_text'], 'label': 0}\n        ])\n\ntrain_df_processed = pd.DataFrame(train_data)\nprint(f\"Loaded {len(train_df_processed)} text samples\")\nprint(train_df_processed.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T15:13:49.043715Z","iopub.execute_input":"2025-09-16T15:13:49.044028Z","iopub.status.idle":"2025-09-16T15:13:49.820516Z","shell.execute_reply.started":"2025-09-16T15:13:49.044000Z","shell.execute_reply":"2025-09-16T15:13:49.819742Z"}},"outputs":[{"name":"stdout","text":"Loaded 190 text samples\n   article_id                                               text  label\n0           0  The VIRSA (Visible Infrared Survey Telescope A...      1\n1           0  The China relay network has released a signifi...      0\n2           1  The project aims to achieve an accuracy level ...      1\n3           1  China\\nThe goal of this project involves achie...      0\n4           2  Scientists can learn about how galaxies form a...      1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom transformers import (\n    AutoTokenizer, AutoModelForSequenceClassification, \n    TrainingArguments, Trainer, DataCollatorWithPadding)\nimport torch \nfrom datasets import Dataset\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T15:59:01.364934Z","iopub.execute_input":"2025-09-16T15:59:01.365283Z","iopub.status.idle":"2025-09-16T15:59:01.370619Z","shell.execute_reply.started":"2025-09-16T15:59:01.365263Z","shell.execute_reply":"2025-09-16T15:59:01.369561Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def prepare_data(texts, labels, tokenizer, max_length=512):\n    encodings = tokenizer(\n        texts,\n        truncation=True,\n        padding=True,\n        max_length=max_length,\n        return_tensors = 'pt'\n    )\n\n    return Dataset.from_dict({\n        'input_ids':encodings['input_ids'],\n        'attention_mask':encodings['attention_mask'],\n        'labels': torch.tensor(labels)\n    })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T16:34:50.888292Z","iopub.execute_input":"2025-09-16T16:34:50.888632Z","iopub.status.idle":"2025-09-16T16:34:50.894515Z","shell.execute_reply.started":"2025-09-16T16:34:50.888609Z","shell.execute_reply":"2025-09-16T16:34:50.893504Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"train_text = train_df_processed['text'].tolist()\ntrain_label = train_df_processed['label'].tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T16:00:29.645176Z","iopub.execute_input":"2025-09-16T16:00:29.645508Z","iopub.status.idle":"2025-09-16T16:00:29.650172Z","shell.execute_reply.started":"2025-09-16T16:00:29.645487Z","shell.execute_reply":"2025-09-16T16:00:29.649090Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(train_text, train_label, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T16:14:34.724482Z","iopub.execute_input":"2025-09-16T16:14:34.724819Z","iopub.status.idle":"2025-09-16T16:14:34.732804Z","shell.execute_reply.started":"2025-09-16T16:14:34.724797Z","shell.execute_reply":"2025-09-16T16:14:34.731604Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Correct model names (note the 'a' in roberta)\ntokenizer = AutoTokenizer.from_pretrained('roberta-base')\nmodel = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('roberta-base', num_labels=2)\ntrain_dataset = prepare_data(train_texts, train_labels, tokenizer)\nval_dataset = prepare_data(val_texts, val_labels, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T16:39:26.608341Z","iopub.execute_input":"2025-09-16T16:39:26.608662Z","iopub.status.idle":"2025-09-16T16:39:28.031380Z","shell.execute_reply.started":"2025-09-16T16:39:26.608642Z","shell.execute_reply":"2025-09-16T16:39:28.030175Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee0be7e6c9d455381cf34145d631c91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90b64177b8814931b477aabaf2d24761"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e00f1560692d4f3eaf9897c9d98135c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e4656c7f4754a7fa8cdff428ef12c77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"757faf9d1c9e4d1ab9569b3d081cf0ca"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T16:40:45.337513Z","iopub.execute_input":"2025-09-16T16:40:45.337877Z","iopub.status.idle":"2025-09-16T16:40:49.157332Z","shell.execute_reply.started":"2025-09-16T16:40:45.337851Z","shell.execute_reply":"2025-09-16T16:40:49.156189Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31bac915855546b58e4359f1fdc3b321"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions ,axis=1)\n    return {\n        'accuracy': accuracy_score(labels, predictions),\n        'f1': f1_score(labels, predictions)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T16:46:06.997019Z","iopub.execute_input":"2025-09-16T16:46:06.997334Z","iopub.status.idle":"2025-09-16T16:46:07.002564Z","shell.execute_reply.started":"2025-09-16T16:46:06.997312Z","shell.execute_reply":"2025-09-16T16:46:07.001546Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100,\n    eval_strategy=\"epoch\",  # Changed from evaluation_strategy\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n     report_to=\"none\"  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T17:12:54.253435Z","iopub.execute_input":"2025-09-16T17:12:54.253803Z","iopub.status.idle":"2025-09-16T17:12:54.261455Z","shell.execute_reply.started":"2025-09-16T17:12:54.253777Z","shell.execute_reply":"2025-09-16T17:12:54.260307Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorWithPadding(tokenizer),\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T17:12:56.845018Z","iopub.execute_input":"2025-09-16T17:12:56.845324Z","iopub.status.idle":"2025-09-16T17:12:56.866136Z","shell.execute_reply.started":"2025-09-16T17:12:56.845300Z","shell.execute_reply":"2025-09-16T17:12:56.865148Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3668688702.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T17:13:01.527550Z","iopub.execute_input":"2025-09-16T17:13:01.528752Z","iopub.status.idle":"2025-09-16T17:13:01.533260Z","shell.execute_reply.started":"2025-09-16T17:13:01.528710Z","shell.execute_reply":"2025-09-16T17:13:01.532249Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T17:13:03.573251Z","iopub.execute_input":"2025-09-16T17:13:03.573630Z","iopub.status.idle":"2025-09-16T17:37:59.120958Z","shell.execute_reply.started":"2025-09-16T17:13:03.573605Z","shell.execute_reply":"2025-09-16T17:37:59.119978Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [57/57 24:30, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.705855</td>\n      <td>0.447368</td>\n      <td>0.618182</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.687686</td>\n      <td>0.526316</td>\n      <td>0.653846</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.618194</td>\n      <td>0.736842</td>\n      <td>0.772727</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=57, training_loss=0.6770312660618832, metrics={'train_runtime': 1494.9114, 'train_samples_per_second': 0.305, 'train_steps_per_second': 0.038, 'total_flos': 119978641244160.0, 'train_loss': 0.6770312660618832, 'epoch': 3.0})"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"def predict_article_pair(model, tokenizer, text1, text2):\n    input1 = tokenizer(text1, return_tensors='pt',truncation=True, padding=True, max_length=512)\n    input2 = tokenizer(text2, return_tensors='pt',truncation=True, padding=True, max_length=512)\n\n    with torch.no_grad():\n        output1 = model(**input1)\n        output2 = model(**input2)\n\n        prob1 = torch.softmax(output1.logits, dim=1)[0][1].item()\n        prob2 = torch.softmax(output2.logits, dim=1)[0][1].item()\n\n    return 1 if prob1 > prob2 else 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T18:09:16.250403Z","iopub.execute_input":"2025-09-16T18:09:16.250717Z","iopub.status.idle":"2025-09-16T18:09:16.257471Z","shell.execute_reply.started":"2025-09-16T18:09:16.250673Z","shell.execute_reply":"2025-09-16T18:09:16.256389Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"def load_text_data(file_path):\n    try:\n        with open(file_path, 'r', encoding='utf-8') as f:\n            return f.read().strip()\n    except:\n        return \"\"\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T18:09:04.601606Z","iopub.execute_input":"2025-09-16T18:09:04.601968Z","iopub.status.idle":"2025-09-16T18:09:04.607917Z","shell.execute_reply.started":"2025-09-16T18:09:04.601944Z","shell.execute_reply":"2025-09-16T18:09:04.606669Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def test_data_set(model, tokenizer, test_dir):\n    test_predictions = []\n    article_folders = [f for f in os.listdir(test_dir) if f.startswith('article_')]\n\n    for article_folder in article_folders:\n        folder_path = os.path.join(test_dir, article_folder)\n        text1 = load_text_data(os.path.join(folder_path, 'file_1.txt'))\n        text2 = load_text_data(os.path.join(folder_path, 'file_2.txt'))\n\n        if not text1 and not text2:\n            print(f\"Warning: Empty files in {article_folder}, defaulting to file_1\")\n            predicted_real = 1\n        else:\n            predicted_real = predict_article_pair(model, tokenizer, text1, text2)\n\n        article_id = article_folder.replace('article_', '')\n\n        test_predictions.append({\n            'id':article_id,\n            'real_text_id':predicted_real\n        })\n\n    return pd.DataFrame(test_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T18:09:05.026277Z","iopub.execute_input":"2025-09-16T18:09:05.026597Z","iopub.status.idle":"2025-09-16T18:09:05.033863Z","shell.execute_reply.started":"2025-09-16T18:09:05.026572Z","shell.execute_reply":"2025-09-16T18:09:05.032859Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def predict_test_set(model, tokenizer, test_dir):\n    test_predictions = []\n    article_folders = [f for f in os.listdir(test_dir) if f.startswith('article_')]\n    \n    for article_folder in article_folders:\n        folder_path = os.path.join(test_dir, article_folder)\n\n        text1 = load_text_data(os.path.join(folder_path, 'file_1.txt'))\n        text2 = load_text_data(os.path.join(folder_path, 'file_2.txt'))\n\n        if not text1 or not text2:\n            print(f\"Warning: Empty files in {article_folder}, defaulting to file_1\")\n            predicted_real = 1\n        else:\n            predicted_real = predict_article_pair(model, tokenizer, text1, text2)\n        \n        article_id = article_folder.replace('article_', '')\n        \n        test_predictions.append({\n            'id': article_id,\n            'real_text_id': predicted_real\n        })\n    \n    return pd.DataFrame(test_predictions)\n\ntest_dir = '/kaggle/input/fake-or-real-the-impostor-hunt/data/test'\nsubmission_df = predict_test_set(model, tokenizer, test_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T18:12:12.587597Z","iopub.execute_input":"2025-09-16T18:12:12.588000Z","iopub.status.idle":"2025-09-16T18:31:33.073043Z","shell.execute_reply.started":"2025-09-16T18:12:12.587966Z","shell.execute_reply":"2025-09-16T18:31:33.072056Z"}},"outputs":[{"name":"stdout","text":"Warning: Empty files in article_0223, defaulting to file_1\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"submission_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T18:38:04.213413Z","iopub.execute_input":"2025-09-16T18:38:04.213757Z","iopub.status.idle":"2025-09-16T18:38:04.220069Z","shell.execute_reply.started":"2025-09-16T18:38:04.213734Z","shell.execute_reply":"2025-09-16T18:38:04.219152Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"(1068, 2)"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"test_dir = '/kaggle/input/fake-or-real-the-impostor-hunt/data/test'\nsubmitted_df = test_data_set(model, tokenizer, test_dir)\nsubmitted_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T18:38:22.171808Z","iopub.execute_input":"2025-09-16T18:38:22.172217Z","iopub.status.idle":"2025-09-16T18:38:23.032739Z","shell.execute_reply.started":"2025-09-16T18:38:22.172191Z","shell.execute_reply":"2025-09-16T18:38:23.031866Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"(1, 2)"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file created!\")\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-16T18:38:25.424543Z","iopub.execute_input":"2025-09-16T18:38:25.425285Z","iopub.status.idle":"2025-09-16T18:38:25.445988Z","shell.execute_reply.started":"2025-09-16T18:38:25.425255Z","shell.execute_reply":"2025-09-16T18:38:25.444897Z"}},"outputs":[{"name":"stdout","text":"Submission file created!\n     id  real_text_id\n0  0192             2\n1  0956             1\n2  0266             2\n3  0435             1\n4  1054             2\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}